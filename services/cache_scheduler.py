import asyncio
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
from datetime import datetime
from crud.crud_place import CRUDPlace
from crud.crud_shared_course import _generate_shared_courses_cache_key, get_shared_courses_stats
from db.session import SessionLocal
from typing import List
from utils.redis_client import redis_client

class CacheScheduler:
    def __init__(self):
        self.scheduler = BackgroundScheduler()
        self.crud_place = CRUDPlace()
        self.is_running = False
        
    def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if self.is_running:
            return
            
        try:
            # 10ë¶„ë§ˆë‹¤ ìºì‹œ ê°±ì‹  ì‘ì—… ë“±ë¡
            self.scheduler.add_job(
                func=self._refresh_popular_places_cache,
                trigger=IntervalTrigger(minutes=10),
                id='refresh_places_cache',
                name='ì¥ì†Œ ëª©ë¡ ìºì‹œ ê°±ì‹ ',
                replace_existing=True,
                max_instances=1  # ë™ì‹œ ì‹¤í–‰ ë°©ì§€
            )
            
            self.scheduler.start()
            self.is_running = True
            print("âœ… ìºì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ - 10ë¶„ë§ˆë‹¤ ìºì‹œ ê°±ì‹ ")
            
            # ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸° ìºì‹œ ìƒì„±
            asyncio.create_task(self._initial_cache_warmup())
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")
    
    def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì •ì§€"""
        if self.scheduler and self.is_running:
            self.scheduler.shutdown()
            self.is_running = False
            print("ğŸ›‘ ìºì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì •ì§€")
    
    def _refresh_popular_places_cache(self):
        """ì¸ê¸° ì¥ì†Œ + ì»¤ë®¤ë‹ˆí‹° ì½”ìŠ¤ ìºì‹œ ê°±ì‹  (ë™ê¸° í•¨ìˆ˜ - ìŠ¤ì¼€ì¤„ëŸ¬ìš©)"""
        try:
            print(f"ğŸ”„ [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ìºì‹œ ê°±ì‹  ì‹œì‘...")
            
            # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
            asyncio.run(self._async_refresh_all_cache())
            
            print(f"âœ… [{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ëª¨ë“  ìºì‹œ ê°±ì‹  ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ê°±ì‹  ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    async def _async_refresh_all_cache(self):
        """ë¹„ë™ê¸° ìºì‹œ ê°±ì‹  ë¡œì§ (ì¥ì†Œ + ì»¤ë®¤ë‹ˆí‹° ì½”ìŠ¤)"""
        async with SessionLocal() as db:
            # ì¸ê¸° ì¥ì†Œ ëª©ë¡ë“¤ (ì£¼ìš” ì¡°í•©ë“¤)
            cache_combinations = [
                # ê¸°ë³¸ ì¸ê¸° ì¥ì†Œ (í›„ê¸° ë§ì€ ìˆœ)
                {'skip': 0, 'limit': 20, 'sort_by': 'review_count_desc'},
                {'skip': 0, 'limit': 50, 'sort_by': 'review_count_desc'},
                
                # í‰ì  ë†’ì€ ìˆœ
                {'skip': 0, 'limit': 20, 'sort_by': 'rating_desc'},
                
                # ìµœì‹ ìˆœ
                {'skip': 0, 'limit': 20, 'sort_by': 'latest'},
                
                # ì´ë¦„ìˆœ (ê¸°ë³¸)
                {'skip': 0, 'limit': 20, 'sort_by': 'name'},
            ]
            
            refreshed_count = 0
            
            for params in cache_combinations:
                try:
                    # ê¸°ì¡´ ìºì‹œ í‚¤ ìƒì„±
                    cache_key = self.crud_place._generate_cache_key(
                        skip=params.get('skip', 0),
                        limit=params.get('limit', 20),
                        category_id=params.get('category_id'),
                        search=params.get('search'),
                        region=params.get('region'),
                        sort_by=params.get('sort_by', 'review_count_desc'),
                        min_rating=params.get('min_rating'),
                        has_parking=params.get('has_parking'),
                        has_phone=params.get('has_phone')
                    )
                    
                    # ê¸°ì¡´ ìºì‹œ ì‚­ì œ
                    redis_client.delete(key=cache_key)
                    
                    # ìƒˆë¡œìš´ ë°ì´í„° ì¡°íšŒ ë° ìºì‹œ ì €ì¥
                    places, total_count = await self.crud_place.get_places_with_filters(
                        db=db,
                        **params
                    )
                    
                    refreshed_count += 1
                    
                except Exception as e:
                    print(f"âŒ ìºì‹œ ê°±ì‹  ì‹¤íŒ¨ (ì¡°í•©: {params}): {e}")
                    continue
            
            print(f"ğŸ”„ ì¥ì†Œ ìºì‹œ {refreshed_count}ê°œ ì¡°í•© ê°±ì‹  ì™„ë£Œ")
            
            # ì»¤ë®¤ë‹ˆí‹° ì½”ìŠ¤ ìºì‹œ ê°±ì‹ 
            await self._refresh_shared_courses_cache(db)
            
            print("ğŸ”„ ëª¨ë“  ìºì‹œ(ì¥ì†Œ + ì»¤ë®¤ë‹ˆí‹° ì½”ìŠ¤) ê°±ì‹  ì™„ë£Œ")
    
    async def _refresh_shared_courses_cache(self, db):
        """ì»¤ë®¤ë‹ˆí‹° ì½”ìŠ¤ ìºì‹œ ê°±ì‹ """
        # ëª¨ë“  shared_courses ê´€ë ¨ ìºì‹œë¥¼ ë¨¼ì € ì‚­ì œ
        print("ğŸ—‘ï¸ ëª¨ë“  shared_courses ìºì‹œ ì‚­ì œ ì¤‘...")
        redis_client.delete(pattern="shared_courses_list:*")
        
        # ì»¤ë®¤ë‹ˆí‹° ì½”ìŠ¤ ì£¼ìš” ì¡°í•©ë“¤
        shared_course_combinations = [
            # ê¸°ë³¸ êµ¬ë§¤ ë§ì€ ìˆœ
            {'skip': 0, 'limit': 20, 'sort_by': 'purchase_count_desc'},
            {'skip': 0, 'limit': 50, 'sort_by': 'purchase_count_desc'},
            
            # í‰ì  ë†’ì€ ìˆœ
            {'skip': 0, 'limit': 20, 'sort_by': 'rating'},
            
            # ì¡°íšŒ ë§ì€ ìˆœ
            {'skip': 0, 'limit': 20, 'sort_by': 'popular'},
            
            # ìµœì‹ ìˆœ
            {'skip': 0, 'limit': 20, 'sort_by': 'latest'},
        ]
        
        refreshed_count = 0
        
        for params in shared_course_combinations:
            try:
                # ì§ì ‘ DBì—ì„œ ë°ì´í„° ì¡°íšŒí•˜ì—¬ ìºì‹œ ê°•ì œ ê°±ì‹ 
                from sqlalchemy import text
                
                # ê¸°ë³¸ ì¿¼ë¦¬ (get_shared_courses_statsì™€ ë™ì¼)
                query = """
                    SELECT shared_course_id as id, shared_course_id, title, shared_by_user_id, 
                           view_count, purchase_count, save_count, price, shared_at,
                           creator_rating, creator_review_text, buyer_review_count, 
                           avg_buyer_rating, overall_rating
                    FROM shared_course_stats 
                    WHERE 1=1
                """
                
                # ì •ë ¬ ì¡°ê±´
                sort_by = params.get('sort_by', 'purchase_count_desc')
                if sort_by == "latest":
                    query += " ORDER BY shared_at DESC"
                elif sort_by == "popular":
                    query += " ORDER BY view_count DESC"
                elif sort_by == "rating":
                    query += " ORDER BY overall_rating DESC"
                elif sort_by == "purchases" or sort_by == "purchase_count_desc":
                    query += " ORDER BY purchase_count DESC"
                else:
                    query += " ORDER BY purchase_count DESC"
                
                # í˜ì´ì§•
                skip = params.get('skip', 0)
                limit = params.get('limit', 20)
                query += f" LIMIT {limit} OFFSET {skip}"
                
                # ë°ì´í„° ì¡°íšŒ
                result = await db.execute(text(query))
                raw_courses = result.fetchall()
                
                # ì´ ê°œìˆ˜ ì¡°íšŒ
                count_result = await db.execute(text("SELECT COUNT(*) as total FROM shared_course_stats"))
                total_count = count_result.scalar()
                
                # ë°ì´í„° ë³€í™˜
                from crud.crud_shared_course import _convert_raw_to_dict
                courses = [_convert_raw_to_dict(row) for row in raw_courses]
                
                # ìºì‹œ í‚¤ ìƒì„± ë° ì €ì¥
                cache_key = _generate_shared_courses_cache_key(
                    skip=skip,
                    limit=limit,
                    sort_by=sort_by,
                    category=params.get('category'),
                    min_rating=params.get('min_rating')
                )
                
                cache_data = {
                    'courses': courses,
                    'total_count': total_count
                }
                redis_client.set(cache_key, cache_data)
                print(f"ğŸ’¾ ê°•ì œ ìºì‹œ ê°±ì‹ : {cache_key} ({len(courses)}ê°œ ì½”ìŠ¤)")
                
                refreshed_count += 1
                
            except Exception as e:
                print(f"âŒ ì»¤ë®¤ë‹ˆí‹° ì½”ìŠ¤ ìºì‹œ ê°±ì‹  ì‹¤íŒ¨ (ì¡°í•©: {params}): {e}")
                import traceback
                traceback.print_exc()
                continue
        
        print(f"ğŸ”„ ì»¤ë®¤ë‹ˆí‹° ì½”ìŠ¤ ìºì‹œ {refreshed_count}ê°œ ì¡°í•© ê°±ì‹  ì™„ë£Œ")
    
    async def _initial_cache_warmup(self):
        """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸° ìºì‹œ ìƒì„±"""
        try:
            print("ğŸ”¥ ì„œë²„ ì‹œì‘ - ì´ˆê¸° ìºì‹œ ìƒì„± ì¤‘...")
            
            # ì„œë²„ ì‹œì‘ì‹œ ëª¨ë“  shared_courses ìºì‹œ ì‚­ì œ
            await self._clear_shared_courses_cache()
            
            await asyncio.sleep(3)  # ì„œë²„ ì™„ì „ ì‹œì‘ ëŒ€ê¸°
            await self._async_refresh_all_cache()
            print("ğŸ”¥ ì´ˆê¸° ìºì‹œ ìƒì„± ì™„ë£Œ!")
            
        except Exception as e:
            print(f"âŒ ì´ˆê¸° ìºì‹œ ìƒì„± ì‹¤íŒ¨: {e}")
    
    async def _clear_shared_courses_cache(self):
        """ì„œë²„ ì‹œì‘ì‹œ ëª¨ë“  shared_courses ìºì‹œ ì‚­ì œ"""
        try:
            # Redisì—ì„œ shared_courses ê´€ë ¨ ëª¨ë“  ìºì‹œ í‚¤ ì¡°íšŒ
            import subprocess
            result = subprocess.run(['redis-cli', 'KEYS', '*shared*'], 
                                  capture_output=True, text=True)
            
            if result.returncode == 0 and result.stdout.strip():
                cache_keys = result.stdout.strip().split('\n')
                
                # ê° ìºì‹œ í‚¤ ì‚­ì œ
                for key in cache_keys:
                    if key.strip():  # ë¹ˆ í‚¤ ì œì™¸
                        redis_client.delete(key=key.strip())
                        print(f"ğŸ—‘ï¸ Redis ìºì‹œ ì‚­ì œ: {key.strip()}")
                
                print(f"ğŸ—‘ï¸ ì´ {len([k for k in cache_keys if k.strip()])}ê°œ shared_courses ìºì‹œ ì‚­ì œ ì™„ë£Œ")
            else:
                print("ğŸ” ì‚­ì œí•  shared_courses ìºì‹œê°€ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âŒ shared_courses ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

# ì „ì—­ ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
cache_scheduler = CacheScheduler()